# üêç Python 3.11+ Concurrency Patterns para Matchmaking

Este documento define as **melhores pr√°ticas de concorr√™ncia** para sistemas de matchmaking em Python, focando em high-concurrency, integridade de dados e arquitetura clean, equivalentes √†s pr√°ticas modernas de Java 21+.

---

## 1. Por Que Migrar de Redis para In-Memory (Asyncio)?

Em Python, o modelo de concorr√™ncia baseado em **Event Loop** (asyncio) oferece vantagens √∫nicas para sistemas I/O bound (como matchmaking e websockets), eliminando muitas classes de race conditions comuns em multithreading.

| Aspecto             | Redis / Celery               | In-Memory (Python Asyncio)                        |
| ------------------- | ---------------------------- | ------------------------------------------------- |
| **Complexidade**    | Requer Broker/DB externo     | Zero depend√™ncias                                 |
| **Lat√™ncia**        | ~1-5ms (network)             | **~0.0001ms** (dict lookup)                       |
| **Concurrency**     | Threads/Processes (pesado)   | Coroutinas (leve)                                 |
| **Race Conditions** | Locks Distribu√≠dos Complexos | **Inexistentes para blocos s√≠ncronos**            |
| **Escalabilidade**  | Horizontal (v√°rias m√°quinas) | Vertical (at√© 1 n√∫cleo*) / Horizontal via Workers |

> **Nota**: O Global Interpreter Lock (GIL) do Python joga a nosso favor aqui. Como apenas uma thread roda por vez, **opera√ß√µes em mem√≥ria sem `await` s√£o at√¥micas por design**, eliminando a necessidade de locks complexos na maioria dos casos.

---

## 2. Fundamentos Python Moderno para Concorr√™ncia

### 2.1 Corrotinas & TaskGroups (vs Virtual Threads)

Enquanto Java usa Virtual Threads para bloquear barato, Python usa **Corrotinas** que suspendem a execu√ß√£o (non-blocking). Python 3.11+ introduziu `TaskGroup` para **Concorr√™ncia Estruturada** (Structured Concurrency).

```python
import asyncio

# ‚ùå Antes (Python antigo): gather ou create_task soltas
# Dif√≠cil tratar erros e cancelamentos em grupo
tasks = [asyncio.create_task(process_player(p)) for p in players]
await asyncio.gather(*tasks)

# ‚úÖ Depois (Python 3.11+): Concorr√™ncia Estruturada
# Se uma falha, todas s√£o canceladas graciosamente. Equivalente a StructuredTaskScope do Java.
async def process_match(players):
    async with asyncio.TaskGroup() as tg:
        for player in players:
            tg.create_task(notify_player_start(player))
    # Aqui garantimos que todos notifica√ß√µes foram enviadas ou tratadas
```

### 2.2 Dataclasses Congeladas (vs Records)

Para garantir integridade e imutabilidade dos dados da a√ß√£o:

```python
from dataclasses import dataclass
from uuid import UUID
import time

# ‚úÖ frozen=True torna a inst√¢ncia imut√°vel e hashable
@dataclass(frozen=True)
class PlayerAction:
    player_id: UUID
    summoner_name: str
    action_type: str
    timestamp: float = time.time()

# Uso
action = PlayerAction(uuid_obj, "Faker", "ACCEPT")
# action.summoner_name = "Troll"  # ‚ùå Levanta FrozenInstanceError
```

### 2.3 Dicts & Atomics (vs ConcurrentHashMap)

Aqui reside o poder do Python Asyncio: **N√£o precisamos de ConcurrentHashMap**.
O event loop √© single-threaded. Se voc√™ n√£o fizer `await` no meio da opera√ß√£o, ningu√©m vai mexer no seu dicion√°rio.

```python
match_acceptances: dict[int, set[str]] = {}

# ‚úÖ AT√îMICO por natureza (sem locks!)
# Nenhuma outra corrotina pode interromper este bloco, pois n√£o h√° 'await'
def process_acceptance_sync(match_id: int, player_name: str):
    if match_id not in match_acceptances:
        match_acceptances[match_id] = set()
    
    match_acceptances[match_id].add(player_name)
    
    if len(match_acceptances[match_id]) == 10:
        return True # Match ready
    return False
```

### 2.4 asyncio.Lock (vs ReentrantLock)

Use `asyncio.Lock` **apenas** quando a se√ß√£o cr√≠tica envolver I/O (um `await`).

```python
lock = asyncio.Lock()
match_state = {}

async def finalize_match(match_id: int):
    # Precisamos de lock aqui porque 'save_to_db' pausa a execu√ß√£o,
    # permitindo que outro request altere 'match_state' durante a pausa.
    async with lock:
        if match_state.get(match_id) == "FINISHED":
            return
        
        # O estado pode mudar enquanto esperamos o DB se n√£o tiver lock
        await save_to_db(match_id) 
        match_state[match_id] = "FINISHED"
```

### 2.5 asyncio.Queue (vs ConcurrentLinkedQueue)

Para garantir a ordem exata de processamento (FIFO). Ideal para filas de Matchmaking.

```python
queue = asyncio.Queue()

# Produtor (API Request)
async def join_queue(player):
    await queue.put(player) # Thread-safe e Async-safe

# Consumidor (Worker Loop)
async def matchmaking_worker():
    while True:
        # Pega o pr√≥ximo na ordem exata de chegada
        player = await queue.get()
        await try_match(player)
        queue.task_done()
```

---

## 3. Arquitetura: Strategy Pattern com Protocol

Para manter a flexibilidade entre In-Memory (Dev/Test) e Redis (Prod), usamos `Protocol` (t√≠pico do Python moderno) ou `ABC`.

```python
from typing import Protocol, List

class MatchStateService(Protocol):
    async def create_match(self, match_id: int, players: List[str]) -> None: ...
    async def accept_match(self, match_id: int, player_name: str) -> None: ...
    async def all_accepted(self, match_id: int) -> bool: ...

# Implementa√ß√£o In-Memory
class InMemoryMatchService:
    def __init__(self):
        self._matches = {} # Dict normal √© suficiente!

    async def create_match(self, match_id: int, players: List[str]):
        self._matches[match_id] = {"pending": set(players), "accepted": set()}

    async def accept_match(self, match_id: int, player_name: str):
        if match_id in self._matches:
            self._matches[match_id]["pending"].discard(player_name)
            self._matches[match_id]["accepted"].add(player_name)

    async def all_accepted(self, match_id: int) -> bool:
        return len(self._matches.get(match_id, {}).get("pending", [])) == 0

# Implementa√ß√£o Redis
class RedisMatchService:
    def __init__(self, redis_client):
        self.redis = redis_client

    async def create_match(self, match_id: int, players: List[str]):
        await self.redis.sadd(f"match:{match_id}:pending", *players)
```

**Inje√ß√£o de Depend√™ncia:**
```python
# config.py
def get_match_service() -> MatchStateService:
    if settings.USE_REDIS:
        return RedisMatchService(redis_client)
    return InMemoryMatchService()
```

---

## 4. Patterns Espec√≠ficos para Matchmaking

### 4.1 Fila de Matchmaking (Ordenada)

Em Python, uma `list` simples pode servir de fila se usarmos `append` e `pop(0)`, mas `asyncio.Queue` √© mais robusta para controle de fluxo.

```python
import asyncio
from dataclasses import dataclass

@dataclass(frozen=True)
class QueuePlayer:
    id: str
    mmr: int
    entry_time: float

class MatchmakingQueue:
    def __init__(self):
        self._queue = asyncio.Queue()
    
    async def add_player(self, player: QueuePlayer):
        await self._queue.put(player)
    
    async def process_queue(self):
        buffer = []
        while True:
            # Pega 10 jogadores ou espera
            while len(buffer) < 10:
                player = await self._queue.get()
                buffer.append(player)
            
            match = self.find_balanced_match(buffer)
            if match:
                await self.start_match(match)
                # Remove os usados do buffer
            else:
                # Retorna jogadores n√£o usados para prioridade?
                # Estrat√©gia complexa: geralmente usa-se listas ordenadas customizadas
                pass
```

### 4.2 Gerenciamento de WebSockets

FastAPI + WebSockets √© o padr√£o ouro moderno.

```python
from fastapi import WebSocket, WebSocketDisconnect

class ConnectionManager:
    def __init__(self):
        # Mapeamento: player_id -> WebSocket
        self.active_connections: dict[str, WebSocket] = {}

    async def connect(self, player_id: str, websocket: WebSocket):
        await websocket.accept()
        # Se j√° tiver conex√£o, fecha a anterior (kick)
        if player_id in self.active_connections:
            await self.active_connections[player_id].close()
        self.active_connections[player_id] = websocket

    def disconnect(self, player_id: str):
        if player_id in self.active_connections:
            del self.active_connections[player_id]

    async def send_personal_message(self, message: str, player_id: str):
        if ws := self.active_connections.get(player_id):
            await ws.send_text(message)
```

---

## 5. Checklist de Migra√ß√£o Java -> Python

| Conceito Java         | Equivalente Python                 | Nota                                              |
| --------------------- | ---------------------------------- | ------------------------------------------------- |
| `Virtual Threads`     | `async`/`await` Coroutines         | Python √© Non-blocking I/O por padr√£o.             |
| `ConcurrentHashMap`   | `dict` (Standard Dictionary)       | Seguro em single-thread (Asyncio).                |
| `ReentrantLock`       | `asyncio.Lock`                     | S√≥ necess√°rio se houver `await` na se√ß√£o cr√≠tica. |
| `Record`              | `@dataclass(frozen=True)`          | Imutabilidade garantida.                          |
| `StructuredTaskScope` | `asyncio.TaskGroup` (Python 3.11+) | Gerenciamento de vida de tasks.                   |
| `Thread.sleep()`      | `await asyncio.sleep()`            | Nunca use `time.sleep()`!                         |

---

## 6. Cuidados e Limita√ß√µes

1.  **Blocking Code √© Proibido**:
    *   NUNCA rode c√≥digo pesado (CPU intensive) ou bloqueante (ex: `requests.get`, `time.sleep`) dentro de uma fun√ß√£o async. Isso para o servidor inteiro.
    *   **Solu√ß√£o**: Use bibliotecas async (`httpx` em vez de `requests`, `asyncpg` em vez de `psycopg2`) ou rode em threadpool: `await asyncio.to_thread(cpu_func)`.

2.  **Escala Vertical**:
    *   Python √© limitado a 1 n√∫cleo por processo (geralmente).
    *   **Solu√ß√£o**: Para produ√ß√£o, rode m√∫ltiplos workers (ex: Gunicorn/Uvicorn com 4 workers). Note que `In-Memory` state **N√ÉO √© compartilhado** entre workers.
    *   Se precisar de m√∫ltiplos workers, voc√™ **DEVE** usar Redis ou uma solu√ß√£o de IPC. Para dev/single-instance, In-Memory funciona perfeitamente.

3.  **Memory Cleanup**:
    *   Objetos em `global dicts` ficam l√° para sempre (Memory Leak).
    *   Use `WeakValueDictionary` se poss√≠vel, ou implemente um cleanup peri√≥dico com `asyncio.create_task(cleanup_loop())`.
