# üìß AutoU - Email Helper

> Aplica√ß√£o web fullstack para classifica√ß√£o autom√°tica de emails usando Intelig√™ncia Artificial.

[![Python](https://img.shields.io/badge/Python-3.11+-3776ab.svg?logo=python&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-009688.svg?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Angular](https://img.shields.io/badge/Angular-20.3+-dd0031.svg?logo=angular)](https://angular.dev/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.4+-3178c6.svg?logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED.svg?logo=docker&logoColor=white)](https://www.docker.com/)
[![Google Cloud Run](https://img.shields.io/badge/Cloud%20Run-Backend-4285F4.svg?logo=googlecloud&logoColor=white)](https://cloud.google.com/run)
[![Vercel](https://img.shields.io/badge/Vercel-Frontend-black.svg?logo=vercel)](https://vercel.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT-412991.svg?logo=openai&logoColor=white)](https://openai.com/)
[![Gemini](https://img.shields.io/badge/Google-Gemini-4285F4.svg?logo=google&logoColor=white)](https://ai.google.dev/)

---

## üåê Demo em Produ√ß√£o

- **Frontend (Vercel)**: [https://email-classifier-frontend-delta.vercel.app](https://email-classifier-frontend-delta.vercel.app)
- **Backend (Cloud Run)**: [https://email-classifier-api-881402891442.southamerica-east1.run.app](https://email-classifier-api-881402891442.southamerica-east1.run.app) *(privado - apenas via Vercel)*
- **API Docs**: [https://email-classifier-api-881402891442.southamerica-east1.run.app/docs](https://email-classifier-api-881402891442.southamerica-east1.run.app/docs) *(requer autentica√ß√£o)*

> ‚ö†Ô∏è **Nota:** O backend est√° configurado como privado e s√≥ aceita requisi√ß√µes autenticadas do Vercel. Acesso direto retorna 403 Forbidden.

---

## üìã Sobre o Projeto

Solu√ß√£o digital para empresas do setor financeiro que lidam com alto volume de emails diariamente. A aplica√ß√£o automatiza a leitura e classifica√ß√£o de emails, sugerindo classifica√ß√µes e respostas autom√°ticas, liberando tempo da equipe para atividades mais estrat√©gicas.

### Funcionalidades

- ‚úÖ **Classifica√ß√£o Autom√°tica**: Classifica emails em categorias predefinidas (Produtivo/Improdutivo)
- ‚úÖ **Gera√ß√£o de Respostas**: Sugere respostas autom√°ticas baseadas no conte√∫do do email
- ‚úÖ **Suporte a M√∫ltiplos Formatos**: Aceita texto direto ou upload de arquivos (.txt, .pdf, .eml, .msg, .mbox)
- ‚úÖ **Interface de Chat**: Experi√™ncia de chat interativa com hist√≥rico de mensagens
- ‚úÖ **Sele√ß√£o de Provider de IA**: Escolha entre OpenAI GPT e Google Gemini dinamicamente
- ‚úÖ **Modal de Preview de Email**: Visualiza√ß√£o profissional do email formatado com op√ß√£o de c√≥pia
- ‚úÖ **Interface Moderna**: UI intuitiva e responsiva com Angular 20+ e Signals
- ‚úÖ **API RESTful**: Backend robusto com FastAPI e Clean Architecture
- ‚úÖ **Docker Compose**: Configura√ß√£o completa para desenvolvimento e produ√ß√£o com hot-reload

### Categorias de Classifica√ß√£o

| Categoria | Descri√ß√£o | Exemplos |
|-----------|-----------|----------|
| **Produtivo** | Requer a√ß√£o ou resposta | Suporte t√©cnico, d√∫vidas, solicita√ß√µes, atualiza√ß√£o sobre casos |
| **Improdutivo** | N√£o requer a√ß√£o imediata | Felicita√ß√µes, agradecimentos, mensagens n√£o relevantes |

### Formatos de Arquivo Suportados

| Formato | Descri√ß√£o | Extens√£o |
|---------|-----------|----------|
| **Texto** | Arquivo de texto simples | `.txt` |
| **PDF** | Documento PDF | `.pdf` |
| **Email** | Arquivo de email padr√£o | `.eml` |
| **Outlook** | Mensagem do Microsoft Outlook | `.msg` |
| **MBOX** | Formato de caixa de correio Unix | `.mbox` |

> **Nota:** Todos os formatos s√£o processados automaticamente, extraindo o conte√∫do do email para classifica√ß√£o.

---

## üõ†Ô∏è Tecnologias

### Backend

- **Python 3.11+** - Linguagem de programa√ß√£o
- **FastAPI** - Framework web ass√≠ncrono de alta performance
- **OpenAI GPT** - API de IA para classifica√ß√£o e gera√ß√£o de respostas
- **Google Gemini** - Alternativa de IA para classifica√ß√£o
- **PyPDF2** - Leitura de arquivos PDF
- **extract-msg** - Leitura de arquivos .msg (Outlook)
- **Pydantic** - Valida√ß√£o de dados e configura√ß√µes
- **Uvicorn** - Servidor ASGI de alta performance
- **Pytest** - Framework de testes

### Frontend

| Tecnologia | Vers√£o | Descri√ß√£o |
|------------|--------|-----------|
| **Angular** | 20.3+ | Framework frontend enterprise moderno |
| **TypeScript** | 5.4+ | Tipagem est√°tica para desenvolvimento escal√°vel |
| **RxJS** | 7.8+ | Programa√ß√£o reativa para requisi√ß√µes HTTP |
| **SCSS** | - | Pr√©-processador CSS para estilos avan√ßados |
| **Signals** | - | Estado reativo moderno (substitui BehaviorSubject) |
| **Angular SSR** | - | Server-Side Rendering para SEO e performance |

**Sintaxe Angular 20+ Utilizada:**

| Feature | Descri√ß√£o |
|---------|-----------|
| `inject()` | Inje√ß√£o de depend√™ncia moderna |
| `signal()` | Estado reativo com signals |
| `computed()` | Propriedades calculadas reativas |
| `input()` | Inputs com signal API |
| `output()` | Outputs tipados |
| `viewChild()` | ViewChild com signal |
| `@if/@for/@switch` | Nova sintaxe de controle de fluxo |
| `standalone: true` | Componentes sem NgModules |
| `ChangeDetectionStrategy.OnPush` | Performance otimizada |

### DevOps

- **Docker** - Containeriza√ß√£o
- **Docker Compose** - Orquestra√ß√£o de containers
- **Google Cloud Run** - Deploy do backend (S√£o Paulo - southamerica-east1)
- **Vercel** - Deploy do frontend com CDN global
- **Google Secret Manager** - Gerenciamento seguro de API keys

---

## ü§ñ Modelos de IA Suportados

### OpenAI (Padr√£o)

| Modelo | Descri√ß√£o | Max Tokens |
|--------|-----------|------------|
| `gpt-4o-mini` | Modelo principal - r√°pido e eficiente | 4.000 |
| `gpt-3.5-turbo` | Fallback - menor custo | 4.000 |

### Google Gemini

| Modelo | Descri√ß√£o | Max Tokens |
|--------|-----------|------------|
| `gemini-2.5-flash` | Modelo principal - alta performance | 8.192 |
| `gemini-2.0-flash` | Fallback prim√°rio | 8.192 |
| `gemini-2.0-flash-lite` | Fallback secund√°rio - mais leve | 8.192 |

> **Nota:** O sistema possui fallback autom√°tico - se o modelo principal falhar, tenta automaticamente os modelos de fallback.

---

## üìê Arquitetura

O projeto segue os princ√≠pios de **Clean Architecture** e **DDD (Domain-Driven Design)**, garantindo separa√ß√£o clara de responsabilidades e alta testabilidade.

### üèóÔ∏è Arquitetura Geral do Sistema

```mermaid
%%{title: "Arquitetura Geral do Sistema"}%%
graph TB
    subgraph "Frontend - Vercel CDN Global"
        A[Angular 20+ SSR] --> B[EmailClassifierChat]
        B --> C[ChatInput]
        B --> D[ChatMessage]
        D --> E[EmailPreviewModal]
    end

    subgraph "State Management"
        F[Signals]
        G[Computed]
        H[LocalStorage]
    end

    subgraph "Backend - Cloud Run S√£o Paulo"
        I[FastAPI]
        I --> J[Use Cases]
        J --> K[Domain]
        J --> L[Infrastructure]
    end

    subgraph "AI Providers"
        M[OpenAI GPT]
        N[Google Gemini]
    end

    subgraph "File Readers"
        O[PDF Reader]
        P[EML Reader]
        Q[MSG Reader]
        R[MBOX Reader]
        S[TXT Reader]
    end

    B --> F
    F --> G
    F --> H
    C --> I
    L --> M
    L --> N
    L --> O
    L --> P
    L --> Q
    L --> R
    L --> S

    style A fill:#dd0031,stroke:#c3002f,color:#fff
    style I fill:#009688,stroke:#00796b,color:#fff
    style M fill:#412991,stroke:#311b92,color:#fff
    style N fill:#4285F4,stroke:#1a73e8,color:#fff
```

### üîÑ Fluxo de Comunica√ß√£o

```mermaid
%%{title: "Fluxo de Comunica√ß√£o da Classifica√ß√£o de Email"}%%
sequenceDiagram
    participant U as Usu√°rio
    participant F as Frontend Angular
    participant V as Vercel Proxy
    participant B as Backend FastAPI
    participant AI as AI Provider
    participant LS as LocalStorage

    Note over U,LS: Fluxo de Classifica√ß√£o de Email

    U->>F: Digita texto ou faz upload
    F->>F: Valida entrada (formato, tamanho)
    F->>F: Adiciona mensagem loading
    F->>LS: Salva hist√≥rico parcial
    F->>V: POST /api/v1/emails/classificar
    V->>B: Proxy para Cloud Run
    B->>B: Valida requisi√ß√£o (Pydantic)
    B->>B: Processa arquivo (se houver)
    B->>AI: Envia para classifica√ß√£o
    AI-->>B: Retorna resultado
    B-->>V: JSON Response
    V-->>F: ClassificacaoResultado
    F->>F: Atualiza mensagem com resultado
    F->>LS: Salva hist√≥rico completo
    F-->>U: Exibe no chat
```

### Camadas do Backend (Clean Architecture)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Interfaces (API REST)          ‚îÇ  ‚Üê Controllers, endpoints
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ      Application (Use Cases)        ‚îÇ  ‚Üê L√≥gica de aplica√ß√£o
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ      Domain (Business Rules)        ‚îÇ  ‚Üê Entidades, Value Objects
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Infrastructure (Implementations)  ‚îÇ  ‚Üê IA, File Readers, NLP
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Princ√≠pios:**

- **Domain**: Cont√©m apenas regras de neg√≥cio puras, sem depend√™ncias externas
- **Application**: Orquestra os casos de uso, define contratos (ports)
- **Infrastructure**: Implementa os contratos (adapters), integra com APIs externas
- **Interfaces**: Exp√µe a API REST, valida entrada/sa√≠da

### Arquitetura do Frontend (Angular 20+)

```mermaid
%%{title: "Arquitetura do Frontend (Angular 20+)"}%%
graph TD
    A[AppComponent] --> B[EmailClassifierChatComponent]
    B --> C[ChatHeaderComponent]
    B --> D[ChatMessageComponent]
    B --> E[ChatInputComponent]
    D --> F[EmailPreviewModalComponent]

    subgraph "Smart Components"
        B
        E
    end

    subgraph "Presentational Components"
        C
        D
        F
    end

    subgraph "Services"
        G[EmailService]
        H[HttpClient]
    end

    B --> G
    G --> H

    style A fill:#1e293b,stroke:#475569,color:#f8fafc
    style B fill:#dd0031,stroke:#c3002f,color:#fff
    style G fill:#22c55e,stroke:#16a34a,color:#fff
```

---

## üöÄ Como Executar

### Pr√©-requisitos

- **Python 3.11+** (para execu√ß√£o local do backend)
- **Node.js 18+** (para execu√ß√£o local do frontend)
- **Docker e Docker Compose** (opcional, para execu√ß√£o via containers)
- Chave de API da **OpenAI** ou **Google Gemini** (pelo menos uma)

### üê≥ Executando com Docker (Recomendado)

A forma mais simples de executar o projeto √© usando Docker Compose:

```bash
# Copiar arquivo de vari√°veis de ambiente
cp .env.example .env

# Editar .env e adicionar suas chaves de API:
# OPENAI_API_KEY=sua_chave_aqui
# GEMINI_API_KEY=sua_chave_aqui (opcional)
# AI_PROVIDER=openai ou gemini

# Executar em modo desenvolvimento (com hot-reload)
docker-compose -f docker-compose.dev.yml up

# Ou executar em modo produ√ß√£o
docker-compose up
```

Ap√≥s iniciar os containers:

- **Backend**: <http://localhost:8000>
  - Documenta√ß√£o Swagger: <http://localhost:8000/docs>
  - Documenta√ß√£o ReDoc: <http://localhost:8000/redoc>
- **Frontend**: <http://localhost:4200>

### üíª Executando Localmente

#### Backend

```bash
# Entrar na pasta do backend
cd backend

# Criar ambiente virtual
python -m venv venv

# Ativar ambiente (Windows)
.\venv\Scripts\activate

# Ativar ambiente (Linux/Mac)
source venv/bin/activate

# Instalar depend√™ncias
pip install -r requirements.txt

# Configurar vari√°veis de ambiente
# Criar arquivo .env na raiz do projeto (ou na pasta backend)
# Editar .env e adicionar suas chaves de API

# Executar servidor
uvicorn main:app --reload --port 8000
```

O backend estar√° dispon√≠vel em: <http://localhost:8000>

- Documenta√ß√£o Swagger: <http://localhost:8000/docs>
- Documenta√ß√£o ReDoc: <http://localhost:8000/redoc>

### Frontend

```bash
# Entrar na pasta do frontend
cd frontend

# Instalar depend√™ncias
npm install

# Executar servidor de desenvolvimento
ng serve --open
```

O frontend estar√° dispon√≠vel em: <http://localhost:4200>

### üé® Interface de Chat

A aplica√ß√£o oferece uma interface de chat moderna e interativa:

- **Hist√≥rico de Mensagens**: Todas as classifica√ß√µes s√£o mantidas em um hist√≥rico conversacional
- **Upload de Arquivos**: Arraste e solte ou selecione arquivos diretamente no chat
- **Sele√ß√£o de Provider**: Escolha o provedor de IA (OpenAI ou Gemini) antes de cada classifica√ß√£o
- **Preview de Email**: Visualize o email formatado profissionalmente em um modal
- **C√≥pia R√°pida**: Copie a resposta sugerida com um clique
- **Scroll Autom√°tico**: O chat rola automaticamente para novas mensagens

### üîÑ Fluxo de Persist√™ncia (LocalStorage)

```mermaid
%%{title: "Fluxo de Persist√™ncia (LocalStorage)"}%%
flowchart TD
    subgraph "Inicializa√ß√£o"
        A[App Inicia] --> B{LocalStorage existe?}
        B -->|Sim| C[Carrega hist√≥rico]
        B -->|N√£o| D[Inicia vazio]
        C --> E[Restaura timestamps]
        E --> F[Atualiza contador IDs]
    end

    subgraph "Durante uso"
        G[Nova mensagem] --> H[Atualiza state]
        H --> I[Salva no LocalStorage]
    end

    subgraph "Novo Chat"
        J[Bot√£o Novo Chat] --> K[Limpa mensagens]
        K --> L[Remove do LocalStorage]
    end
```

---

## üì° API Endpoints

A API RESTful est√° documentada automaticamente em `/docs` (Swagger UI) e `/redoc`.

### Principais Endpoints

| M√©todo | Endpoint | Descri√ß√£o |
|--------|----------|-----------|
| `GET` | `/api/v1/emails/providers` | Lista provedores de IA dispon√≠veis e seus status |
| `POST` | `/api/v1/emails/classificar` | Classificar email por texto (com par√¢metro `provider` opcional) |
| `POST` | `/api/v1/emails/classificar/arquivo` | Classificar email por arquivo (.txt, .pdf, .eml, .msg, .mbox) |
| `GET` | `/api/v1/emails/health` | Health check do servi√ßo |

### Exemplos de Uso

#### 1. Listar Provedores de IA

**Request:**

```bash
curl -X GET "http://localhost:8000/api/v1/emails/providers"
```

**Response:**

```json
{
  "default": "openai",
  "providers": {
    "openai": {
      "available": true,
      "model": "gpt-4o-mini",
      "fallback_models": ["gpt-3.5-turbo"],
      "max_tokens": 4000
    },
    "gemini": {
      "available": true,
      "model": "gemini-2.5-flash",
      "fallback_models": ["gemini-2.0-flash", "gemini-2.0-flash-lite"],
      "max_tokens": 8192
    }
  }
}
```

#### 2. Classificar por Texto

**Request:**

```bash
curl -X POST "http://localhost:8000/api/v1/emails/classificar" \
  -H "Content-Type: application/json" \
  -d '{
    "conteudo": "Ol√°, preciso de ajuda com meu pedido #12345. Quando ser√° entregue?",
    "provider": "openai"
  }'
```

> **Nota:** O par√¢metro `provider` √© opcional. Se n√£o fornecido, ser√° usado o provider padr√£o configurado.

**Response:**

```json
{
  "categoria": "Produtivo",
  "confianca": 0.95,
  "resposta_sugerida": "Prezado(a), agradecemos o contato. Vamos verificar o status do seu pedido #12345 e retornaremos em breve com informa√ß√µes sobre a entrega."
}
```

#### 3. Classificar por Arquivo

**Request:**

```bash
curl -X POST "http://localhost:8000/api/v1/emails/classificar/arquivo?provider=gemini" \
  -F "arquivo=@email.eml"
```

**Response:**

```json
{
  "categoria": "Improdutivo",
  "confianca": 0.88,
  "resposta_sugerida": "Agradecemos sua mensagem de felicita√ß√µes. Desejamos um √≥timo Natal e um pr√≥spero Ano Novo!",
  "nome_arquivo": "email.eml"
}
```

> **Formatos Suportados:** `.txt`, `.pdf`, `.eml`, `.msg` (Outlook), `.mbox`
>
> **Tamanho M√°ximo:** 5MB por arquivo

### Documenta√ß√£o Interativa

Acesse a documenta√ß√£o interativa da API:

- **Swagger UI**: <http://localhost:8000/docs>
- **ReDoc**: <http://localhost:8000/redoc>

---

## üß™ Testes

O projeto inclui testes unit√°rios e de integra√ß√£o para garantir a qualidade do c√≥digo.

### Backend

```bash
# Entrar na pasta do backend
cd backend

# Executar todos os testes
pytest

# Executar testes com cobertura de c√≥digo
pytest --cov=. --cov-report=html

# Executar testes espec√≠ficos
pytest tests/unit/application/test_classificar_email_use_case.py

# Executar com verbose
pytest -v
```

Os relat√≥rios de cobertura ser√£o gerados em `backend/htmlcov/index.html`.

### Frontend

```bash
# Entrar na pasta do frontend
cd frontend

# Executar testes unit√°rios
npm test

# Executar testes em modo watch
npm test -- --watch
```

---

## üìÅ Estrutura de Arquivos

```
desafio_fullstack/
‚îú‚îÄ‚îÄ backend/                      # Backend FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ domain/                   # Camada de dom√≠nio (regras de neg√≥cio)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entities/             # Entidades de dom√≠nio
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ email.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ value_objects/        # Objetos de valor
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ classificacao_resultado.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py         # Exce√ß√µes de dom√≠nio
‚îÇ   ‚îú‚îÄ‚îÄ application/              # Camada de aplica√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ports/                # Interfaces (portas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dtos/                 # Data Transfer Objects
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ use_cases/            # Casos de uso
‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/           # Camada de infraestrutura
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai/                   # Implementa√ß√µes de IA
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai_classificador.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_classificador.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ classificador_factory.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_readers/         # Leitores de arquivo
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ leitor_txt.py     # Arquivos de texto
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ leitor_pdf.py     # Arquivos PDF
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ leitor_eml.py     # Arquivos de email (.eml)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ leitor_msg.py     # Arquivos Outlook (.msg)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ leitor_mbox.py    # Arquivos MBOX
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nlp/                  # Processamento de linguagem natural
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ preprocessador.py
‚îÇ   ‚îú‚îÄ‚îÄ interfaces/               # Camada de interface
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api/v1/               # API REST
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ email_controller.py
‚îÇ   ‚îú‚îÄ‚îÄ config/                   # Configura√ß√µes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py
‚îÇ   ‚îú‚îÄ‚îÄ tests/                    # Testes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unit/                 # Testes unit√°rios
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ integration/          # Testes de integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # Depend√™ncias Python
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile                # Dockerfile do backend
‚îÇ
‚îú‚îÄ‚îÄ frontend/                     # Frontend Angular
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/       # Componentes Angular
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ email-classifier-chat/    # Interface de chat principal
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ email-upload/             # Upload de emails
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ email-preview-modal/       # Modal de preview de email
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resultado-classificacao/   # Exibi√ß√£o de resultados
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat-message/              # Componente de mensagem do chat
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat-input/                # Input do chat
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat-header/               # Cabe√ßalho do chat
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/         # Servi√ßos HTTP
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ email.service.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/           # Interfaces TypeScript
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ environments/         # Vari√°veis de ambiente
‚îÇ   ‚îú‚îÄ‚îÄ package.json              # Depend√™ncias Node.js
‚îÇ   ‚îî‚îÄ‚îÄ angular.json              # Configura√ß√£o Angular
‚îÇ
‚îú‚îÄ‚îÄ docs/                         # Documenta√ß√£o e screenshots
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml            # Docker Compose (produ√ß√£o)
‚îú‚îÄ‚îÄ docker-compose.dev.yml        # Docker Compose (desenvolvimento)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md                     # Este arquivo
‚îú‚îÄ‚îÄ Projeto-escopo.md             # Escopo do projeto
‚îî‚îÄ‚îÄ ETAPAS-DESENVOLVIMENTO.md     # Etapas de desenvolvimento
```

---

## üîß Configura√ß√£o

### Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes vari√°veis:

| Vari√°vel | Descri√ß√£o | Padr√£o | Obrigat√≥rio |
|----------|-----------|--------|-------------|
| `OPENAI_API_KEY` | Chave da API OpenAI | - | Sim* |
| `GEMINI_API_KEY` | Chave da API Google Gemini | - | Sim* |
| `AI_PROVIDER` | Provedor de IA: `openai` ou `gemini` | `openai` | N√£o |
| `OPENAI_MODEL` | Modelo da OpenAI a usar | `gpt-4o-mini` | N√£o |
| `OPENAI_MODELS_FALLBACK` | Modelos de fallback OpenAI | `gpt-3.5-turbo` | N√£o |
| `OPENAI_MAX_TOKENS` | M√°ximo de tokens OpenAI | `4000` | N√£o |
| `GEMINI_MODEL` | Modelo do Gemini a usar | `gemini-2.5-flash` | N√£o |
| `GEMINI_MODELS_FALLBACK` | Modelos de fallback Gemini | `gemini-2.0-flash,gemini-2.0-flash-lite` | N√£o |
| `GEMINI_MAX_TOKENS` | M√°ximo de tokens Gemini | `8192` | N√£o |
| `CORS_ORIGINS` | Origens permitidas (separadas por v√≠rgula) | `http://localhost:4200,http://localhost:3000` | N√£o |
| `DEBUG` | Modo debug | `false` | N√£o |

\* Pelo menos uma chave de API (OpenAI ou Gemini) √© obrigat√≥ria, dependendo do `AI_PROVIDER` escolhido.

### Exemplo de arquivo .env

```env
# Provedor de IA (openai ou gemini)
AI_PROVIDER=openai

# OpenAI (obrigat√≥rio se AI_PROVIDER=openai)
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_MODEL=gpt-4o-mini
OPENAI_MODELS_FALLBACK=gpt-3.5-turbo
OPENAI_MAX_TOKENS=4000

# Google Gemini (obrigat√≥rio se AI_PROVIDER=gemini)
GEMINI_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxx
GEMINI_MODEL=gemini-2.5-flash
GEMINI_MODELS_FALLBACK=gemini-2.0-flash,gemini-2.0-flash-lite
GEMINI_MAX_TOKENS=8192

# CORS
CORS_ORIGINS=http://localhost:4200,http://localhost:3000

# Debug
DEBUG=false
```

---

## üîÆ Destaques T√©cnicos

### Backend (Python + FastAPI)

#### Clean Architecture com Ports & Adapters

```python
# Port (Interface)
class ClassificadorPort(ABC):
    @abstractmethod
    def classificar(self, conteudo: str) -> ClassificacaoResultado:
        pass

# Adapter (Implementa√ß√£o)
class OpenAIClassificador(ClassificadorPort):
    def __init__(self, client: OpenAI, model: str):
        self.client = client
        self.model = model

    def classificar(self, conteudo: str) -> ClassificacaoResultado:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": conteudo}]
        )
        return self._parse_response(response)
```

#### Factory Pattern para Provedores de IA

```python
class ClassificadorFactory:
    @staticmethod
    def criar(provider: str) -> ClassificadorPort:
        if provider == "openai":
            return OpenAIClassificador(client, settings.openai_model)
        elif provider == "gemini":
            return GeminiClassificador(client, settings.gemini_model)
        raise ValueError(f"Provider n√£o suportado: {provider}")
```

#### Valida√ß√£o com Pydantic

```python
class ClassificarEmailRequest(BaseModel):
    conteudo: str = Field(..., min_length=1, max_length=50000)
    provider: Optional[AIProvider] = None

class ClassificacaoResultado(BaseModel):
    categoria: CategoriaEmail
    confianca: float = Field(..., ge=0, le=1)
    resposta_sugerida: str
    modelo_usado: Optional[str] = None
```

### Frontend (Angular 20+ com Signals)

#### State Management com Signals

```typescript
// State reativo com Signals
readonly mensagens = signal<ChatMessage[]>([]);
readonly carregando = signal(false);
readonly providerSelecionado = signal<AIProvider>('openai');

// Propriedades derivadas com computed
readonly temMensagens = computed(() => this.mensagens().length > 0);
readonly podeEnviar = computed(() => 
    !this.carregando() && this.conteudoEmail().trim().length > 0
);
```

#### Inje√ß√£o de Depend√™ncia Moderna

```typescript
export class EmailClassifierChatComponent {
    private readonly emailService = inject(EmailService);
    private readonly platformId = inject(PLATFORM_ID);
    private readonly isBrowser = isPlatformBrowser(this.platformId);
}
```

#### Sintaxe Moderna de Template

```html
@if (carregando()) {
    <div class="loading-skeleton">...</div>
}

@for (msg of mensagens(); track msg.id) {
    <app-chat-message [message]="msg" />
}

@switch (resultado().categoria) {
    @case ('Produtivo') { <span class="badge-success">‚úì</span> }
    @case ('Improdutivo') { <span class="badge-warning">‚óã</span> }
}
```

#### Standalone Components

```typescript
@Component({
    selector: 'app-chat-message',
    standalone: true,
    imports: [PercentPipe, EmailPreviewModalComponent],
    templateUrl: './chat-message.component.html',
    changeDetection: ChangeDetectionStrategy.OnPush
})
export class ChatMessageComponent {
    readonly message = input.required<ChatMessage>();
    readonly copiarResposta = output<string>();
}
```

#### Persist√™ncia SSR-Safe com LocalStorage

```typescript
const CHAT_STORAGE_KEY = 'autou-email-classifier-chat-history';

private carregarHistoricoChat(): void {
    if (!this.isBrowser) return; // SSR-safe

    const stored = localStorage.getItem(CHAT_STORAGE_KEY);
    if (stored) {
        const mensagens = JSON.parse(stored).map((msg: any) => ({
            ...msg,
            timestamp: new Date(msg.timestamp)
        }));
        this.mensagens.set(mensagens);
    }
}
```

### DevOps

#### Vercel Configuration (vercel.json)

```json
{
  "rewrites": [
    {
      "source": "/api/:path*",
      "destination": "https://email-classifier-api-xxx.run.app/api/:path*"
    }
  ],
  "headers": [
    {
      "source": "/assets/(.*)",
      "headers": [{ "key": "Cache-Control", "value": "public, max-age=31536000, immutable" }]
    },
    {
      "source": "/(.*)",
      "headers": [
        { "key": "X-Content-Type-Options", "value": "nosniff" },
        { "key": "X-Frame-Options", "value": "DENY" },
        { "key": "X-XSS-Protection", "value": "1; mode=block" }
      ]
    }
  ]
}
```

#### Docker Compose para Desenvolvimento

```yaml
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    command: uvicorn main:app --reload --host 0.0.0.0

  frontend:
    build: ./frontend
    ports:
      - "4200:4200"
    volumes:
      - ./frontend:/app
    command: ng serve --host 0.0.0.0
```

---

## üéØ Funcionalidades Implementadas

### Interface do Usu√°rio

- ‚úÖ **Interface de Chat Interativa**: Experi√™ncia de chat com hist√≥rico de mensagens, scroll autom√°tico e visualiza√ß√£o clara das classifica√ß√µes
- ‚úÖ **Persist√™ncia Local (LocalStorage)**: Hist√≥rico de conversas salvo automaticamente no browser, SSR-safe
- ‚úÖ **Upload de Arquivos**: Suporte para m√∫ltiplos formatos (.txt, .pdf, .eml, .msg, .mbox) com valida√ß√£o de tamanho (m√°x 5MB)
- ‚úÖ **Sele√ß√£o Din√¢mica de Provider**: Interface permite escolher entre OpenAI e Gemini em tempo real
- ‚úÖ **Modal de Preview de Email**: Visualiza√ß√£o profissional do email formatado com tema dark/light
- ‚úÖ **Feedback Visual**: Indicadores de carregamento (skeleton), erros e sucesso nas opera√ß√µes
- ‚úÖ **Novo Chat**: Bot√£o para limpar hist√≥rico e iniciar nova conversa

### Backend

- ‚úÖ **Clean Architecture**: Separa√ß√£o clara de responsabilidades (Domain, Application, Infrastructure, Interfaces)
- ‚úÖ **M√∫ltiplos Leitores de Arquivo**: Suporte nativo para formatos de email comuns
- ‚úÖ **Factory Pattern**: Sistema flex√≠vel para adicionar novos provedores de IA
- ‚úÖ **Tratamento de Erros**: Exce√ß√µes espec√≠ficas de dom√≠nio com mensagens claras
- ‚úÖ **Health Check**: Endpoint para monitoramento do servi√ßo
- ‚úÖ **Valida√ß√£o de Dados**: Pydantic para valida√ß√£o de entrada e sa√≠da

### DevOps

- ‚úÖ **Docker Compose**: Configura√ß√£o completa para desenvolvimento e produ√ß√£o
- ‚úÖ **Hot Reload**: Desenvolvimento com recarregamento autom√°tico (backend e frontend)
- ‚úÖ **Health Checks**: Monitoramento autom√°tico dos containers
- ‚úÖ **Deploy Cloud Run**: Backend rodando no Google Cloud Run (S√£o Paulo)
- ‚úÖ **Deploy Vercel**: Frontend com CDN global e proxy para o backend
- ‚úÖ **Secrets Management**: Chaves de API gerenciadas pelo Google Secret Manager

## üìù Melhorias Futuras

- [ ] Adicionar testes de integra√ß√£o end-to-end
- [ ] Implementar cache de classifica√ß√µes no backend
- [ ] Adicionar autentica√ß√£o e autoriza√ß√£o
- [ ] Hist√≥rico persistente em banco de dados (al√©m do LocalStorage)
- [ ] Adicionar dashboard de m√©tricas e analytics
- [ ] Configurar CI/CD com GitHub Actions
- [ ] Suporte a mais formatos de arquivo (docx, odt, etc.)
- [ ] Exporta√ß√£o de resultados (CSV, JSON)
- [ ] Modo offline com Service Workers

---

## ‚òÅÔ∏è Deploy em Produ√ß√£o

### Infraestrutura Atual

| Componente | Plataforma | Regi√£o | Tecnologia | URL |
|------------|------------|--------|------------|-----|
| **Frontend** | Vercel | CDN Global | Angular 20+ SSR | [email-classifier-frontend-delta.vercel.app](https://email-classifier-frontend-delta.vercel.app) |
| **Backend** | Google Cloud Run | S√£o Paulo | FastAPI + Python | Privado (apenas via Vercel) |
| **Secrets** | Google Secret Manager | - | - | Chaves OpenAI e Gemini |
| **Proxy** | Vercel Serverless Functions | - | Node.js | `/api/*` ‚Üí Cloud Run (autenticado) |
| **Persist√™ncia** | LocalStorage | Browser | - | Hist√≥rico de conversas |

### üîí Arquitetura de Seguran√ßa

O backend no Cloud Run √© **privado** e aceita apenas requisi√ß√µes autenticadas do Vercel, protegendo contra uso indevido da API de IA.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        ARQUITETURA SEGURA                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ   ‚îÇ Browser  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Vercel (Proxy)     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Cloud Run       ‚îÇ    ‚îÇ
‚îÇ   ‚îÇ Usu√°rio  ‚îÇ     ‚îÇ  Serverless Funcs   ‚îÇ     ‚îÇ  (Privado)       ‚îÇ    ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                              ‚îÇ                         ‚ñ≤               ‚îÇ
‚îÇ                              ‚îÇ    Token JWT            ‚îÇ               ‚îÇ
‚îÇ                              ‚îî‚îÄ‚îÄ Service Account ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   ‚úÖ Usu√°rio via Vercel    ‚Üí Funciona (autenticado automaticamente)    ‚îÇ
‚îÇ   ‚ùå Acesso direto (curl)  ‚Üí Bloqueado (403 Forbidden)                 ‚îÇ
‚îÇ   ‚ùå Postman sem auth      ‚Üí Bloqueado (403 Forbidden)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Componentes de Seguran√ßa:**

| Componente | Descri√ß√£o |
|------------|-----------|
| **Service Account** | `vercel-invoker@classificador-email-desafio.iam.gserviceaccount.com` |
| **IAM Role** | `roles/run.invoker` (apenas invoca√ß√£o do Cloud Run) |
| **Autentica√ß√£o** | Identity Token (JWT) gerado automaticamente |
| **Proxy Functions** | Serverless Functions no Vercel que adicionam autentica√ß√£o |

**Estrutura do Proxy (Vercel Serverless Functions):**

```
frontend/api/
‚îî‚îÄ‚îÄ v1/
    ‚îî‚îÄ‚îÄ emails/
        ‚îú‚îÄ‚îÄ providers.js           # GET  /api/v1/emails/providers
        ‚îú‚îÄ‚îÄ classificar.js         # POST /api/v1/emails/classificar
        ‚îî‚îÄ‚îÄ classificar/
            ‚îî‚îÄ‚îÄ arquivo.js         # POST /api/v1/emails/classificar/arquivo
```

### Deploy do Backend (Cloud Run)

```bash
cd backend

# Build e deploy
gcloud run deploy email-classifier-api \
    --source . \
    --region southamerica-east1 \
    --port 8000 \
    --memory 512Mi --cpu 1 --max-instances 1 \
    --no-allow-unauthenticated \
    --set-secrets "OPENAI_API_KEY=openai-api-key:latest,GEMINI_API_KEY=gemini-api-key:latest"
```

### Configurar Seguran√ßa (Cloud Run Privado)

```bash
# 1. Criar Service Account para o Vercel
gcloud iam service-accounts create vercel-invoker \
    --display-name="Vercel Cloud Run Invoker"

# 2. Dar permiss√£o de invoker
gcloud run services add-iam-policy-binding email-classifier-api \
    --member="serviceAccount:vercel-invoker@SEU_PROJETO.iam.gserviceaccount.com" \
    --role="roles/run.invoker" \
    --region=southamerica-east1

# 3. Gerar chave JSON
gcloud iam service-accounts keys create vercel-service-account-key.json \
    --iam-account=vercel-invoker@SEU_PROJETO.iam.gserviceaccount.com

# 4. (Opcional) Remover acesso p√∫blico se existir
gcloud run services remove-iam-policy-binding email-classifier-api \
    --member="allUsers" \
    --role="roles/run.invoker" \
    --region=southamerica-east1
```

> ‚ö†Ô∏è **Importante:** O arquivo `vercel-service-account-key.json` cont√©m credenciais sens√≠veis. Nunca commite no Git!

### Deploy do Frontend (Vercel)

**1. Configurar vari√°vel de ambiente no Vercel Dashboard:**

- Acesse: <https://vercel.com/dashboard> ‚Üí Seu projeto ‚Üí Settings ‚Üí Environment Variables
- Adicione:
  - **Nome:** `GOOGLE_SERVICE_ACCOUNT_KEY`
  - **Valor:** Conte√∫do completo do arquivo `vercel-service-account-key.json`
  - **Environments:** Production, Preview, Development

**2. Deploy:**

```bash
cd frontend

# Instalar depend√™ncias (inclui google-auth-library)
npm install

# Deploy
vercel --prod
```

> Para mais detalhes, consulte o arquivo [DEPLOY.md](DEPLOY.md) e [docs/CLOUD-RUN-PRIVADO.md](docs/CLOUD-RUN-PRIVADO.md).

---

## üõ†Ô∏è Desenvolvimento

### Estrutura de Branches

- `main` - Branch principal (produ√ß√£o)
- `develop` - Branch de desenvolvimento
- `feature/*` - Novas funcionalidades
- `fix/*` - Corre√ß√µes de bugs

### Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

### Padr√µes de C√≥digo

- **Backend**: Seguir PEP 8, usar Black e isort para formata√ß√£o
- **Frontend**: Seguir Angular Style Guide, usar Prettier
- **Commits**: Mensagens claras e descritivas

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## üë• Autor

Desenvolvido como parte do desafio t√©cnico fullstack para a **AutoU**.

## üìö Recursos Adicionais

- [Documenta√ß√£o FastAPI](https://fastapi.tiangolo.com/)
- [Documenta√ß√£o Angular](https://angular.io/docs)
- [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)
- [OpenAI API](https://platform.openai.com/docs)
- [Google Gemini API](https://ai.google.dev/docs)
- [Google Cloud Run](https://cloud.google.com/run/docs)
- [Vercel Documentation](https://vercel.com/docs)

---

## üí¨ Coment√°rios

### Decis√µes T√©cnicas

**Frontend - Angular:** Optei por utilizar Angular para o frontend por ser o framework que tenho maior dom√≠nio e facilidade. Isso permitiu um desenvolvimento mais √°gil e confi√°vel, aproveitando ao m√°ximo as funcionalidades modernas do framework (Signals, SSR, entre outras).

**Backend - Python:** A escolha por Python foi baseada nos requisitos da vaga, mesmo possuindo mais experi√™ncia em Java. A decis√£o permitiu entregar uma solu√ß√£o funcional e bem estruturada seguindo os princ√≠pios de Clean Architecture, demonstrando adaptabilidade e capacidade de trabalhar com diferentes tecnologias.

### Infraestrutura e Deploy

**Frontend - Vercel:** O frontend est√° deployado na Vercel, aproveitando a CDN global e o deploy autom√°tico via Git. A plataforma oferece excelente performance e facilidade de configura√ß√£o.

**Backend - Cloud Run:** O backend est√° rodando no Google Cloud Run na regi√£o de S√£o Paulo (southamerica-east1). √â importante notar que o servi√ßo possui um comportamento de hiberna√ß√£o/acordar conforme o uso - isso significa que na primeira requisi√ß√£o ap√≥s um per√≠odo de inatividade, o servi√ßo pode levar aproximadamente **5 segundos para inicializar completamente** antes de processar a requisi√ß√£o. Esse √© um comportamento esperado do Cloud Run para otimiza√ß√£o de custos.

**Seguran√ßa - Cloud Run Privado:** O Cloud Run foi configurado como **privado** (sem acesso p√∫blico direto) para proteger contra uso indevido da API de IA. Apenas o Vercel consegue invocar o backend atrav√©s de uma Service Account do Google Cloud com a role `roles/run.invoker`. As requisi√ß√µes passam por Serverless Functions no Vercel que adicionam autentica√ß√£o JWT automaticamente. Isso significa que tentativas de acessar a API diretamente (via curl, Postman, etc.) retornam **403 Forbidden**, enquanto usu√°rios acessando normalmente pelo site Vercel funcionam perfeitamente.

**Docker Compose para Desenvolvimento:** Configurei um `docker-compose.dev.yml` separado para facilitar o desenvolvimento local, com hot reload configurado tanto para o backend quanto para o frontend. Isso permite uma experi√™ncia de desenvolvimento mais fluida, com altera√ß√µes sendo refletidas automaticamente sem necessidade de rebuild dos containers.

### Status do Projeto

A aplica√ß√£o est√° **100% deployada e funcional** em produ√ß√£o, com todas as funcionalidades implementadas e testadas. O ambiente de desenvolvimento est√° configurado e pronto para uso, facilitando futuras melhorias e manuten√ß√µes.
